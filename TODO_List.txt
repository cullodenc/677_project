This TODO list will be updated periodically as new features are added, and new ideas for improvements are created
The items below are grouped by the type of task, and listed to some degree by their priority, along with relavent details

*********************************************************************************
TODO IN-PROGRESS
Features that are currently being worked on, in order of priority (excluding cleanup tasks)
*********************************************************************************

--Update output parser
  | STATUS: Currently built to accommodate verification, still needs to be updated to include performance data

--Timing Update Bug
  | STATUS: Patched for now, requires further fixing in the future to enable more accurate timing


*********************************************************************************
TODO WORK QUEUE
Features to be developed soon
*********************************************************************************

--Add device attribute checking
  | STATUS: Calculations of design dimensions in terms of device hardware limitations allows for minimum device requirements to be determined
  | DETAILS:
            - Precomputation hardware check to alert user to unmet system requirements at a minimum
            - FUTURE: Precompilation check to accommodate different hardware capabilities

--Add Parameter Build Options
  | STATUS: Requires integration with attribute checking to ensure user defined parameters do not exceed device limitations
  | DETAILS:
      -Compile time parameters can allow for multiple architectures to be compared without the need to modify source code
      -Some parameters could potentially be set at runtime, depending on the level of integration in device functions for each variable

--Fix Input EOF Handling
  | STATUS: Pseudo implemented, but does not work as intended. Requires a more stable solution for final product

--Create Escape Routes (Error Handling)
  | STATUS: Limited to only a few mining error conditions for now, needs to be more broadly applied to the entire program

--Add profiling visuals for mining
  | STATUS: Basic profiling added, still requires a bit of organization and cleanup

--Optimize Merkle Root calculations
  | STATUS: - Attempted with limited success, postponed for now due to complexity and low impact on performance



*********************************************************************************
FIXME CRITICAL
*********************************************************************************
Critical issues that have yet to be resolved

  Continue cleanup of unneccessary functions/variables, merge duplicates, etc.

  Timing Update Bug(TIMING EVENT QUEUE BLOCKING)
    | Summary:
     -Timing updates blocked by too many operations being added to execute asynchronously
     -Can be resolved by removing events, but may arise later if more asynchronous stream operations are added
    | Solution: Restructure code to minimize queued operations
      -Event Reduction could reduce unneccessarily queued items
      -Additional intermediate stages could reduce items added to the queue at one time


*********************************************************************************
BUG
Bugs that currently exist in the program, arising under certain circumstances
*********************************************************************************

--Timing Update Bug (QUEUE BLOCKING)
  | DATE FOUND: 1-12-2019
  | DATE IDENTIFIED: 1-15-2019
  | DATE FIXED: N/A
  | PRIORITY: Medium
  | STATUS: IN-PROGRESS
    -Partially fixed at the cost of slightly decreased timing accuracy.
    -More methods for accurate timing are being explored
  | DETAILS:
    -This bug presented itself through a complete halting of the mining process, with no new blocks after a substantial amount of time had passed
    -The worker kernels indicated a problem with the current time variable, as the kernel time updates showed no change over the course of several minutes
    -This bug was experienced near difficulty 0x1d00ffff (MODIFIER=0), with 8 or more workers
    -This problem persisted for timing stored in constant or global memory, on new and old miners
    -This bug can be replicated by running the miner with the settings: ./cuda_miner -diff 0 -w 8 (May not appear if you get lucky and multiple times per block arent needed)
  | CAUSE:
    -Blocked by adding timing events to too many concurrent streams, new timing methods are needed
  | DEBUGGING:
    -Using the default stream to directly obtain information on the timing update, it was found that the update becomes blocked until at least one worker completes its block
    -If all workers are working on blocks which require an updated time, the time will never update and the program will stall
  | ATTEMPTED FIXES:
    --Setting all streams with the nonblocking flag, with a higher priority on the timing stream
      -Result: Failed, problem persists, and the timing stream simply queues the timing updates without successful completion
    --Removing event record after the kernel call from previous streams
      -SUCCESS! - But this prevents accurate timing statistics from being taken, further optimizations required to eliminate this issue completely
    --TODO: The problem seems to only arise when the number of timed CUDA streams is greater than the number of available CPU cores.
      -Detect the number of available CPU cores and store the value
      -If the number of workers requested is less than the available cores, run with accurate timing methods (CUDA events)
      -If the number of workers requested exceeds the number of available CPU cores, use different timing methods
          -For low difficulty with a minimal probability of stalling, continue using accurate timing
          -For high difficulty with a more significant potential to stall out, use safe timing on the CPU side.
              -Potentially add an escape mechanism, such that if a stall is encountered, halt the GPU process to allow for timing update.
      -HACK As of 9/11/2019, the bug has been disabled by recording the stop time in the core loop instead of by adding an event to trigger in each worker stream




*********************************************************************************
TODO CUDA
Code improvements which are neccessary to have a fully functional program
*********************************************************************************


--Optimize Merkle Root calculations
  | PRIORITY: Medium High
  | STATUS: POSTPONED
    -Attempted with limited success, postponed for now due to complexity and low impact on performance
  | Details:
    -The merkle root operation is currently quite bulky on shared memory, and limited in its potential for performance and scaling
    -Ideally, this algorithm would be adjusted to use built in shuffle functions to speed up the coalescing of data into the final thread
    -Storing the data in texture memory could also help to improve the performance for bigger transaction sets
    -TODO Add an extra merkle loop to process datasets larger than the maximum number of available threads
  | SOLUTION NOTES:
    - Use shuffle operations to coalesce hash data into a single thread
    - Use the new mining operation for hashing [DONE 2-7-2019]

--Add device attribute checking
  | Priority: Medium High
  | Details:
    -The current setup is designed to work for a specific multiprocessor design
    -If a different device is used which doesn't have enough resources, the program should identify this issue and warn the user
    -TODO:
      -Add function to check that the device meets the minimum requirements to run the program
      -Add compile time options to modify the design parameters such as the multiprocessors available or memory limits, etc
      -Create a precompilation program which detects gpu properties and adds the neccessary changes to the compile options without user intervention

--Add Parameter Build Options
  | Priority: Medium High
  | Details:
    -Testing and comparison of different build options (such as blocks allocated or threads per block) is currently timing consuming, as these options are hard coded as defined variables
    -A more versatile testing method would be needed to compare various build options side by side, without the need for compilation and source code modification in between
  | Solution:
    -Add compile time options for modifying the architecture, such that multiple different designs can be compiled at once for testing

--Create Escape Routes
  | PRIORITY: Medium High
  | Details:
    - NOTE: SEE "Better Error Handling" in MISC
    -In the case of an error during execution, the program needs to properly handle the error and respond accordingly.
    -All faults should also be logged in the error.out file
    -For critical faults (ex. files won't open, cuda device not detected, cuda function failed):
      -Detect the nature of the error, log, and proceed to shutdown the program (stop miners, free memory, close files, etc)
    -For non-critical faults (ex. parent buffer is full & program stalled, worker input EOF, etc):
      -Log and handle accordingly
      -TODO Ensure that input EOF handling is working properly, such that the worker is marked as done and the miner exits early if all input files are finished.

--Improve Program Input Options
  | Priority: Medium High
  | Details:
    - The current input options are sufficient for development up to this point, but may require updates in the future
    - Ex. Input options for attributes such as the input and output files would be helpful for controlling testing


--Create Designated Copy Streams
  | PRIORITY: Medium High
  | Details:
    -As a potential fix for the timing bug, add dedicated streams for memory copies, which may remove any deadlocks that are created between streams
    -The ideal scenario would use two high priority memory transfer streams, creating full duplex communication to the GPU
    -NOTE Only two streams would be unwise, as this would lead to inner stream dependencies, stalling the completion of kernels which finish out of order
          A more practical option is to create unique streams for each worker, and then have them wait on events before beginning
    -IDEA For concurrent timing, have the write back trigger from a mining completion event, and queue the event after writing back has finished
    -This fix may be more complicated than neccessary for fixing the timing bug, and has a higher probability of causing further bugs which would be more difficult to track down

--Add profiling visuals for mining
  | PRIORITY: Low
  | STATUS: UPDATED 1-18-2019
    -Basic detailed profiling added
  | Details:
    -Similar to the benchmark and testing functions, add profiling support to the main miner which shows the stream names/activity, and better displays the blocks mined and difficulty scaling
    -At a basic level, this would simply show the activity, while a more elegant display would use color scaling to better depict the changes in the miner over time
    -TODO Add more informative color schemes and labels for blocks and difficulty scaling
          Re-organize profiling calls into functions to clean up the main host process code
    -TODO Consolidate profiling functions to reduce the clutter in core mining functions

--Use Stream Callbacks
  | PRIORITY: Low
  | Details:
    -The current method of iterating over worker streams and looking for a stream that is ready is an unreliable process that prioritizes based on stream order.
    -Callbacks could provide a better method for starting the next block, based on when each stream is ready instead of which one is next in line
    -With callbacks added, the main process would primarily focus on updating constant variables and calling the parent stream when neccessary
    -The downside is that this would require significant modifications to the existing code, and would probably be best implemented on another branch incase complications arise
    -Callbacks may also make it easier to implement CPU multithreading later on
    -NOTE CUDA functions can't be called from callbacks, so these would be best used to initiate other functions such as file I/O instead of timing
    -These will work best for intermediate status outputs if multiple streams are used, such as to print the mining start log after merkle hashing has completed


--Add File Details header
  | PRIORITY: Medium
  | Details:
    -The input files currently just use a very large number of inputs to prevent ever becoming empty
    -This may change if workers merkle hash the data in the input files
    -A header in each input file with details such as file length would enable the program to preemptively discover if a longer input file is needed
  | UPDATE:
    -Most of the output files currently don't provide any additional information aside from the result data
    -Including output file headers could assist in any post-processing activities
    -For input files, a total file size could be used to calculate if a larger file needs to be generated
    -For output files, details such as the starting difficulty (hex) and merkle tree sizes can help reduce user intervention needed for post-processing scripts


--Input File EOF Handling
  | PRIORITY: Medium High
  | Details:
    -There is currently pseudo input file error handling in the program, but it does not always perform as needed
    -The input files currently just use a very large number of inputs to prevent ever becoming empty, so EOF handling is currently not an issue
    -When there is an EOF risk, the file reader should be updated to properly handle EOF, and stop a worker if an EOF occurs
  | UPDATE (From further investigation and duplicate issue)
    -The program currently does not properly handle the early termination of an input file for workers
    -Instead, it appears that the program continues running after EOF is reached, using all zero values as the inputs
    -For this implementation, it may be best to simply start over from the beginning of the file when this condition is reached.
    -For a functional implementation, it would be best for the program to either halt, or more likely wait for additional inputs from the distributed network (which is out of this project scope)
    -This is not a critical component for this phase of development, as the program still continues to operate after EOF is reached


*********************************************************************************
TODO Project Management
*********************************************************************************

--Add makefile building
  | PRIORITY: High
  | Details:
    -The current scripts used to build the program are quite limited, and will not work on every system used, thus a more complex build process via a make file would be useful to
      match system constraints and link in the neccessary libraries
    -A make file with room for additional arguments could enable the use of a make script or even a short program which can take in user provided arguments for how the code should be built
    -These arguments would most likely get passed to the compiler, such that the preprocessor can choose the appropriate functions and variables to implement

--Split the code into filesystem
  | PRIORITY: Medium High
  | Dependencies: makefile building
  | Details:
    -Although combining the code into a single file initially provided an easier means of managing everying, it has since become cumbersome due to the large file size.
    -Once the core code has been updated to the extent that system wide changes are no longer needed, it would be ideal to split the file by functionality and scope
    -This requires the use of a makefile to simplify the linking process, and eliminate any performance losses that come from external device functions

--Implement Macro for Logging
  | PRIORITY: Low
  | Dependencies: makefile building
  | Details:
    -The current method of printing logs is messy and error prone
    -This is primarily due to the use of string concatenation to create the log messages
    -Macro functions should be created to simplify the logging process
    -This fix will need to include an overhaul of all the calls to logging functions
    -The debug function will most likely need the debug variable passed in at compilation

--Update Documentation
  | PRIORITY: Medium
  | Details:
    -The documentation for all of the project functions is pretty limited at this point, consisting mainly of inline comments and brief summaries of functionality
    -During the process of splitting up the main file, it would be beneficial to simultaneously write some more thorough descriptions for each function, such as arguments, purpose, etc
    -This is best saved for a later point in the process when most of the functions have been fully defined and optimized, preventing the need to constantly update the descriptions
    -The descriptions should eventually be copied into a more complete documentation file, and an inline documentation system similar to javadoc would be great as well (though it would require many changes)

--Update Github description
  | PRIORITY: Medium Low
  | Details:
    -The description has to be updated at some point if this project is to have any hope of gaining attention and more developers
    -This will be postponed until the project is at a more stable point of development, and more documentation on the project components are available
    -It would also be beneficial to have split the project into more organized files at that point

--Create a make helper
  | Details: Low
    -If a large number of customizations can be added to the make process, it may be useful to create a make helper application which prompts the user for various inputs
    -This would be more of a luxary feature, as a simple script could be used to implement default customizations to speed up builds during development


*********************************************************************************
TODO PYTHON
*********************************************************************************

--Update output parser
  | PRIORITY: High
  | Status: IN-PROGRESS
  | Details:
    -The current python parser is set up to load and verify data from the miner output files
    -Additional features are needed aside from the verificaion component that has been added
    -Timing and performance analytics need to be gathered for further analysis
    -A function is needed to organize the required data in spreadsheets, sets up for further data analysis
    -More input flags would be nice to avoid accidentally overwriting an expensive test, especially for mining

--Create an analysis script
  | PRIORITY: Medium
  | Details:
    -Having the results parsed out into a timing spreadsheet is extremely useful for performance analysis, but the process of graphing/analyzing these results can still be quite time consuming
    -Ideally, either a script or a set of functions can be created to automatically generate statistics and graphs for each design run
    -Some of the goal features may not be possible with the tools that are currently used (such as xlsxwriter) and more research and tools will most likely be needed


*********************************************************************************
TODO MISCELLANEOUS
*********************************************************************************



--Better Error Handling
  | PRIORITY: Medium
  | Details:
    -Minimum error handling has been implemented so far, and it would be beneficial to add error handling for a variety of cases
    -CUDA: Proper error handlers should be added to ensure each CUDA function has executed completely (and the errors should be logged and resolved, or trigger a safe exit)
    -C: Handlers or try catch statements should be used to avoid crashes from runtime errors in the non-cuda code
    -EXIT: A functionality should be added to allow the program to safely stop before exiting (such as with a user input)


--Create windows compatible alternatives
  | PRIORITY: Medium
  | Dependencies: Makefiles
  | Details:
    -Much of the development for this project has been done on a linux system, and as such there are several incompatibilities with Windows OS
    -Some of these differences include the inability to use bash scripts on windows, and the creation of directories using linux formats
    -Windows OS users would obviously make up a significant portion of end users, and thus these incompatibilities need to be resolved
    -The easiest solution would be to check for the OS using a make file, and sending preprocessor arguments to define functions accordingly

--Create Better Profiling Scripts
  | PRIORITY: Medium Low
  | Details:
    -The current profiler script is quite basic, and it only sets certain compiler options to enable profiling libraries and functions
    -To speed up the profiling process, it would be nice to have a script which started the visual profiler with all the neccessary options, saving a couple minutes on each launch and reducing the frequency of errors


--Language Update
  | PRIORITY: Low
  | Details:
    -The current code is primarily C, with a little bit of C++ mixed in as cuda functions
    -Updating this to C++ could provide many object oriented advantages that aren't possible with C
    -This would also take a lot of effort, and is highly error prone. Thus this task is best reserved for a later point


*********************************************************************************
FIXME CLEANUP
Changes that should be made to improve the code and eliminate stale content
*********************************************************************************

--Remove obsolete functions, update with replacements
  | PRIORITY: Medium
  | STATUS: IN-PROGRESS
    - Many obsolete functions have been removed, additional simplification requires conversion of testing functions from bytes to words
  | Details:
    -A fair number of the functions used have at some point been either replaced with an improved version or removed due to obsolete functionality
    -These should be deleted when they are no longer of any use

--Variable cleanup
  | DATE: 1-18-2019
  | PRIORITY: Low Medium
  | STATUS: IN-PROGRESS
    -Completed for basic worker and parent variables by consolidating vars into WORKLOAD structs. More may be neccessary at a later point
  | Details:
    -Some of the variables used in the program are not neccessary, messy, or redundant, and should be optimized if they are of minimal risk
    -Examples include variable declarations midway through a function, variables which no longer serve a purpose in a specific context, or variables contain duplicate data
    -These should be fixed when encountered as long as the risk of introducing bugs is low

--Profiling cleanup
  | PRIORITY: Low Medium
  | Details:
    -Although the profiling parameters are useful for visualizing the mining process, they distract from the core code for the project
    -Various methods should be used to consolidate and clean up profiling code to make core functions more legible
    -POSSIBLE SOLUTIONS:
      -Iteration: Some of the nested profiling calls could rely on a struct to help coordinate color and position sequences
      -Consolidation: Repeated blocks of profiling activity could be grouped together in separately declared functions
      -Relocation: Many of the profiler functions take up space in the main function, and could be moved within other functions
      -Wrapping: In some instances, a profiling wrapper could be used to attach a profiling domain to a miner or block, enabling it to end accordingly without needing to be called explicitly

--Eliminate old files
  | PRIORITY: Low
  | Details:
    -The original source files used for this project were originally kept as backup references, but are unneccessary at this point, and should be deleted (or at least moved out of the active repo)


*********************************************************************************
IDEA FUTURE IMPROVEMENTS
*********************************************************************************

--Implement CPU Multithreading
  | PRIORITY: Medium (depending)
  | Details:
    -The current application is not currently hindered by blocking on the CPU, but improvements such as using full transaction blocks would lead to a large time being spent on loading data
    -Since only a single CPU core can effectively control the GPU at a time, it would be advantageous to free up activity on that core by offloading non-device related work to other threads
    -This can include most of the file management, and potentially network or cluster related functions when later modules are added
    -With the current developer skill set, the use of OpenMP and MPI would be the primary options for this multithreading
    -Using this method would require a major overhaul of the current code, and would most likely be postponed until the larger blockchain framework was developed
    -These features would be implemented as follows to meet the needs of a high performance computing environment:
      --OpenMP (or similar shared memory framework):
        -The shared memory design of OpenMP would make is an ideal environment for file control and worker management
        -Ideally, the threads would each be assigned a worker, and they would prefetch transaction data and write results to the neccessary files without blocking the host execution
        -Thread assignment would also need to be managed such that the host cores are always available to handle communication with the GPU
        -For multi GPU systems and HPC clusters, a more complex framework would be needed to control which GPU is being used, and their associated CPU threads
        -At least one host core is needed, with the potential to have one core per GPU if the system allows it. Additional cores for inter cluster communication and networking may also be needed
      --MPI:
        -If more than one cluster is used, a framework such as MPI would be more suitable for performing communication between nodes
        -This would be done after the shared memory implementation, as it currently can't be tested for free (a cloud based solution would most likely be used)
      --OTHER:
        -To enable full networking capabilities, other IP compatible frameworks would be needed
        -Developer knowledge for merging a C application to use web frameworks are limited (aside from server hosting using Javascript or PHP), and more research will be needed


--Functional Blockchain Application:
  | Details:
    -This is a late stage addition, after all the ground work has been laid out, and the analysis results are promising
    -Since the development team is small, and the amount of required functionality is massive, it may be optimal to fork some of these features off existing open-source blockchains
    -Using existing sources would also lower the risk of creating vulnerabilities which have already been discovered (and subsequently exploited)

    --Networking capabilities
      | Details:
        -This one should be pretty obvious, you can't have a distributed public ledger unless its distributed, so secure networking between miners and users is a must
        -Part of this portion of the application will also be management of the ledger, and security features to mitigate risks like DDoS

    --Transaction functionality
      | Details:
        -If tokens are used to attract users to the blockchain, then it is a requirement to enable transactions of coins, and verification of both transactions and accounts
        -This is a massive category due to the inherent security risks, along with the options for features like smart contracts

    --Chain Management
      | Details:
        -A branched chain will require a variety of maintenence features to keep it running and secure, these range from functions to determine when a block is securely on the chain, to stale branch pruning

    --Parent Branch
      | Details:
        -The current parent chain infrastructure doesn't really add very much to the chain in terms of security and functionality.
        -Additional packages will need to be added to update the parent chain security, such as linking with child chains, and miner cross verification
        -The possibility to implement proof of stake exists for the parent chain, but this is dependant on there actually being something at stake

    --Miscellaneous
      | Details:
        -Lots of other features exist to make a complete application, and they will be added in as the project progresses.
        -Other potential features for different purposes other than cryptocurrencies may be a promising avenue of development
        -A sidechain similar to namecoin could be used to keep track of all the child chains, while also providing a barrier of entry to create a child chain, limiting the potential for abuse



/*--------------------------------------------------------------------------------------------------------------------------------*/
BACKLOG - Completed items, along with the completion date
/*--------------------------------------------------------------------------------------------------------------------------------*/

--Create Output Verification
  | PRIORITY: Medium High
  | Status: COMPLETED 10-22-2019
  | Details:
    -Some means of verification already exist to test the algorithm functionality, and numerous tests have been done to ensure result validity
    -Further verification should be done with a simple python script that iterates over the mining results, and checks for any errors that may have occurred during mining
    -This is only listed lower than the parser as obtaining performance results is slightly more important at this stage in the development process for determining what needs improvement
    -TODO The use of merkle hashing increases the need for python verification, as it makes verification of results by manual inspection substantially more difficult
  | NOTE: Components needed for output verification
    -Shell script which runs mining algorithm and passes the appropriate parameters to the python script for verification
    -Basic method to test mining hash (double SHA256) for accuracy
    -Method to test merkle tree finding accuracy
    -Method to test accuracy of input merkle hashing
    -Method to test parent hashing and accuracy

--Use merkle root data for workers
  | PRIORITY: Medium
  | Dependencies: Optimize Merkle Root, Optimize hash functions
  | STATUS: COMPLETED 9-18-2019
    - The input variable for workers was changed to a buffer variable
    - Additional functions were added to handle merkle hashing
    -Merkle hashing was not fully optimized, primarily due to the complexity of the operation, which would yield limited performance improvements
  | Details:
    -The current algorithm is able to emulate the complexity of a blockchain application, but it lacks the capability to actually process transactions
    -This should be updated such that the workers each read a block of data from their file and calculate the merkle root prior to mining the data
    -Using this method may require later optimizations so that the host doesn't get blocked on reading from the input files
    -This method will also utilize a greater portion of the available memory copy bandwidth, which is currently drastically underutilized

--Change Device Functions
  | PRIORITY: Medium High
  | STATUS: COMPLETED 2-7-2019
    - All device functions were updated as part of the new set of mining algorithms
  | Details:
    -Several of the device related functions have variables which are either not used, or are used to both send and receive data
    -This may not lead to the best performance, and should be updated such that the same memory isn't used to both send and receive

--Integrate New Mining Algorithm
  | PRIORITY: High
  | STATUS: COMPLETED 2-7-2019
    - New functions have been successfully integrated into the mining core[2-7-2019]
    - Functions integrated, and duplicate or deprecated functions removed
  | Details:
    - A new benchmark kernel was created to improve the mining speed while maintaining a low memory overhead
    - This kernel needs to be integrated into the main mining functions

--Optimize other hash functions
  | PRIORITY: Medium
  | STATUS: COMPLETED 2-6-2019
    - Mining functions optimized using the same hashing core as the previous benchmark hash
  | Details:
    -Add acceleration for the other hash functions used, similar to the improvements added in for the 80 Byte double hash used in the new miner kernel


--Fix Benchmark Kernel
  | PRIORITY: High
  | STATUS: COMPLETED 2-5-2019
    - Used atomic operations to add iterations per block, giving a more accurate metric
  | Details:
    - The benchmark kernel currently produces overinflated results if the register usage is higher than 32
    - This is due to only 1 iteration count being taken from the first block, while in reality each block with have a slightly different iteration count


--Fix Core Mining Kernel
  | PRIORITY: High
  | STATUS: COMPLETED 2-5-2019
    - Reworked the kernel core to only use 32 registers per thread
    - Added atomic operations to the main loops to prevent write conflicts
      - Atomic flags also promote faster breaking from loops
    - Kernel templates for the number of blocks enable the for loops to operate without additional memory overhead
  | Details:
    - The mining kernel is currently inefficient due to an overusage of registers due to a number of reasons:
      - The order of accesses to variables can impact the number of registers allocated
      - The method used to break out of the mining loop can drastically alter register usage
    - The mining kernel is error prone at extrememly low difficulties, and is prone to multiple threads overwriting the result variables simultaneously, resulting in incorrect outputs
    - The for loop needs a constant input for the maximum iteration and increment size, or else an additional 8 registers are used

--Better Device Debugging
  | PRIORITY: Medium
  | STATUS: COMPLETED 2-3-2019
    - Added conditional compiler option DEV_DEBUG which enables a variety of print statements when passed to nvcc with value 1, 2, or 3
  | Details:
    - Print statements on the device side are expensive, and can add unwanted registers if located in an active location
    - A method for better device debugging is needed


--Worker Variable Consolidation
  | PRIORITY: Medium
  | STATUS: COMPLETED 1-18-2019
    -Worker and Parent variables were successfully consolidated into WORKLOAD structs
    -This allows for simplified addition of mining variables
  | Details:
    -The current code has a large number of variables which are currently independent, and quite a mess
    -Update the code to group the variables together into structs, helping with code organization
